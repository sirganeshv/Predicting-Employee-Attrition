{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "0    246\n",
      "1     48\n",
      "Name: e.Attrition, dtype: int64\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.864795918367\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.15306122449\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.120426829268\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[235  11]\n",
      " [ 34  14]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       246\n",
      "          1       0.56      0.29      0.38        48\n",
      "\n",
      "avg / total       0.82      0.85      0.83       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693]]\n",
      "[0.86479591836734693]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x00000233CE060378>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.857993197279\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.170223577236\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[245   1]\n",
      " [ 46   2]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "          1       0.67      0.04      0.08        48\n",
      "\n",
      "avg / total       0.81      0.84      0.78       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693], [0.84013605442176875, 'SelectKBest+LR', (array([117, 128, 129], dtype=int64),), 0.85799319727891155]]\n",
      "[0.86479591836734693, 0.85799319727891155]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x00000233CE060378>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693], [0.84013605442176875, 'SelectKBest+LR', (array([117, 128, 129], dtype=int64),), 0.85799319727891155], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),), 0.8392857142857143]]\n",
      "[0.86479591836734693, 0.85799319727891155, 0.8392857142857143]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693], [0.84013605442176875, 'SelectKBest+LR', (array([117, 128, 129], dtype=int64),), 0.85799319727891155], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'KNN', (array([], dtype=int64),), 0.8392857142857143]]\n",
      "[0.86479591836734693, 0.85799319727891155, 0.8392857142857143, 0.8392857142857143]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.836734693878\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.839285714286\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.163265306122\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.19512195122\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[246   0]\n",
      " [ 48   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      1.00      0.91       246\n",
      "\n",
      "avg / total       0.84      1.00      0.91       246\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693], [0.84013605442176875, 'SelectKBest+LR', (array([117, 128, 129], dtype=int64),), 0.85799319727891155], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'KNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.8392857142857143]]\n",
      "[0.86479591836734693, 0.85799319727891155, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.850340136054\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.83843537415\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.149659863946\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0955284552846\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[241   5]\n",
      " [ 39   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.98      0.92       246\n",
      "          1       0.64      0.19      0.29        48\n",
      "\n",
      "avg / total       0.83      0.85      0.81       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693], [0.84013605442176875, 'SelectKBest+LR', (array([117, 128, 129], dtype=int64),), 0.85799319727891155], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'KNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.8392857142857143], [0.85034013605442171, 'RandomForest', (array([ 28,  63,  74,  75,  95,  96, 111, 113, 127, 129, 219, 221, 234, 279], dtype=int64),), 0.83843537414965985]]\n",
      "[0.86479591836734693, 0.85799319727891155, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.83843537414965985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.840136054422\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.875850340136\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.159863945578\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.170223577236\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[239   7]\n",
      " [ 40   8]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       246\n",
      "          1       0.53      0.17      0.25        48\n",
      "\n",
      "avg / total       0.80      0.84      0.80       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.84693877551020413, 'LogisticRegression', (array([ 20,  22,  27,  28,  36,  39,  49,  74,  75,  89, 104, 113, 126,\n",
      "       127, 129, 146, 147, 198, 201, 219, 220, 246, 250, 276, 291], dtype=int64),), 0.86479591836734693], [0.84013605442176875, 'SelectKBest+LR', (array([117, 128, 129], dtype=int64),), 0.85799319727891155], [0.83673469387755106, 'SelectKBest+kNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'KNN', (array([], dtype=int64),), 0.8392857142857143], [0.83673469387755106, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.8392857142857143], [0.85034013605442171, 'RandomForest', (array([ 28,  63,  74,  75,  95,  96, 111, 113, 127, 129, 219, 221, 234, 279], dtype=int64),), 0.83843537414965985], [0.84013605442176875, 'XGBoost', (array([ 22,  28,  49,  63,  75, 116, 126, 127, 129, 146, 219, 220, 234,\n",
      "       270, 275], dtype=int64),), 0.87585034013605434]]\n",
      "[0.86479591836734693, 0.85799319727891155, 0.8392857142857143, 0.8392857142857143, 0.8392857142857143, 0.83843537414965985, 0.87585034013605434]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.85034013605442171, 'RandomForest', (array([ 28,  63,  74,  75,  95,  96, 111, 113, 127, 129, 219, 221, 234, 279], dtype=int64),), 0.83843537414965985]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "0    260\n",
      "1     34\n",
      "Name: e.Attrition, dtype: int64\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.858001265558\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0309954751131\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   8]\n",
      " [ 23  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       260\n",
      "          1       0.58      0.32      0.42        34\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676]]\n",
      "[0.85800126555766676]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x00000233CE060378>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.877551020408\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.849476116368\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.122448979592\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.197285067873\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[251   9]\n",
      " [ 27   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       260\n",
      "          1       0.44      0.21      0.28        34\n",
      "\n",
      "avg / total       0.85      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676], [0.87755102040816324, 'SelectKBest+LR', (array([ 34,  57,  75,  86,  89, 107, 122, 128, 129, 144, 158, 190, 195,\n",
      "       241, 285, 293], dtype=int64),), 0.84947611636755604]]\n",
      "[0.85800126555766676, 0.84947611636755604]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x00000233CE060378>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676], [0.87755102040816324, 'SelectKBest+LR', (array([ 34,  57,  75,  86,  89, 107, 122, 128, 129, 144, 158, 190, 195,\n",
      "       241, 285, 293], dtype=int64),), 0.84947611636755604], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82738237456726249]]\n",
      "[0.85800126555766676, 0.84947611636755604, 0.82738237456726249]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676], [0.87755102040816324, 'SelectKBest+LR', (array([ 34,  57,  75,  86,  89, 107, 122, 128, 129, 144, 158, 190, 195,\n",
      "       241, 285, 293], dtype=int64),), 0.84947611636755604], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'KNN', (array([], dtype=int64),), 0.82738237456726249]]\n",
      "[0.85800126555766676, 0.84947611636755604, 0.82738237456726249, 0.82738237456726249]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.827382374567\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[260   0]\n",
      " [ 34   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       260\n",
      "\n",
      "avg / total       0.88      1.00      0.94       260\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676], [0.87755102040816324, 'SelectKBest+LR', (array([ 34,  57,  75,  86,  89, 107, 122, 128, 129, 144, 158, 190, 195,\n",
      "       241, 285, 293], dtype=int64),), 0.84947611636755604], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'KNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.82738237456726249]]\n",
      "[0.85800126555766676, 0.84947611636755604, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.824842205939\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.130769230769\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   7]\n",
      " [ 27   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       260\n",
      "          1       0.50      0.21      0.29        34\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676], [0.87755102040816324, 'SelectKBest+LR', (array([ 34,  57,  75,  86,  89, 107, 122, 128, 129, 144, 158, 190, 195,\n",
      "       241, 285, 293], dtype=int64),), 0.84947611636755604], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'KNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'RandomForest', (array([ 12,  39,  44,  89, 103, 107, 123, 168, 183, 190, 200, 202, 216, 244], dtype=int64),), 0.82484220593868696]]\n",
      "[0.85800126555766676, 0.84947611636755604, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249, 0.82484220593868696]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853769071518\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0309954751131\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   7]\n",
      " [ 24  10]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       260\n",
      "          1       0.59      0.29      0.39        34\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.89455782312925169, 'LogisticRegression', (array([ 16,  42,  57,  75,  84,  86,  89,  97, 107, 122, 129, 144, 149,\n",
      "       190, 195, 215, 241, 244, 293], dtype=int64),), 0.85800126555766676], [0.87755102040816324, 'SelectKBest+LR', (array([ 34,  57,  75,  86,  89, 107, 122, 128, 129, 144, 158, 190, 195,\n",
      "       241, 285, 293], dtype=int64),), 0.84947611636755604], [0.88435374149659862, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'KNN', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.82738237456726249], [0.88435374149659862, 'RandomForest', (array([ 12,  39,  44,  89, 103, 107, 123, 168, 183, 190, 200, 202, 216, 244], dtype=int64),), 0.82484220593868696], [0.89455782312925169, 'XGBoost', (array([ 16,  75,  84,  86,  89, 103, 107, 128, 144, 154, 183, 190, 192,\n",
      "       202, 215, 241, 244], dtype=int64),), 0.85376907151841819]]\n",
      "[0.85800126555766676, 0.84947611636755604, 0.82738237456726249, 0.82738237456726249, 0.82738237456726249, 0.82484220593868696, 0.85376907151841819]\n",
      "Stored 'accuracy_arr' (list)\n",
      "Final: [0.89455782312925169, 'XGBoost', (array([ 16,  75,  84,  86,  89, 103, 107, 128, 144, 154, 183, 190, 192,\n",
      "       202, 215, 241, 244], dtype=int64),), 0.85376907151841819]\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "0    261\n",
      "1     33\n",
      "Name: e.Attrition, dtype: int64\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.884353741497\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.853741496599\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.115646258503\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.160571229537\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[253   8]\n",
      " [ 26   7]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       261\n",
      "          1       0.47      0.21      0.29        33\n",
      "\n",
      "avg / total       0.86      0.88      0.86       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952]]\n",
      "[0.85374149659863952]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x00000233CE060378>)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.84693877551\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0581678857541\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[257   4]\n",
      " [ 27   6]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       261\n",
      "          1       0.60      0.18      0.28        33\n",
      "\n",
      "avg / total       0.87      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952], [0.89455782312925169, 'SelectKBest+LR', (array([  5,  56,  67,  71, 130, 154, 200, 240, 257, 268], dtype=int64),), 0.84693877551020391]]\n",
      "[0.85374149659863952, 0.84693877551020391]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function chi2 at 0x00000233CE060378>)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform'))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952], [0.89455782312925169, 'SelectKBest+LR', (array([  5,  56,  67,  71, 130, 154, 200, 240, 257, 268], dtype=int64),), 0.84693877551020391], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82653061224489799]]\n",
      "[0.85374149659863952, 0.84693877551020391, 0.82653061224489799]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952], [0.89455782312925169, 'SelectKBest+LR', (array([  5,  56,  67,  71, 130, 154, 200, 240, 257, 268], dtype=int64),), 0.84693877551020391], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'KNN', (array([], dtype=int64),), 0.82653061224489799]]\n",
      "[0.85374149659863952, 0.84693877551020391, 0.82653061224489799, 0.82653061224489799]\n",
      "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "  n_features_to_select=1, step=1, verbose=0)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[261   0]\n",
      " [ 33   0]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       261\n",
      "\n",
      "avg / total       0.89      1.00      0.94       261\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952], [0.89455782312925169, 'SelectKBest+LR', (array([  5,  56,  67,  71, 130, 154, 200, 240, 257, 268], dtype=int64),), 0.84693877551020391], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'KNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.82653061224489799]]\n",
      "[0.85374149659863952, 0.84693877551020391, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799]\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=Fa...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.887755102041\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.826530612245\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.112244897959\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.126436781609\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   9]\n",
      " [ 24   9]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       261\n",
      "          1       0.50      0.27      0.35        33\n",
      "\n",
      "avg / total       0.87      0.89      0.87       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952], [0.89455782312925169, 'SelectKBest+LR', (array([  5,  56,  67,  71, 130, 154, 200, 240, 257, 268], dtype=int64),), 0.84693877551020391], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'KNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'RandomForest', (array([ 13,  41,  55,  56,  67,  87, 133, 142, 147, 157, 186, 191, 200,\n",
      "       202, 203, 238, 249, 286], dtype=int64),), 0.82653061224489788]]\n",
      "[0.85374149659863952, 0.84693877551020391, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.82653061224489788]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\u001b[1mACCURACY : \u001b[0;0m 0.894557823129\n",
      "\u001b[1mCROSS VALIDATION SCORE : \u001b[0;0m 0.844387755102\n",
      "\u001b[1mMEAN SQUARED ERROR : \u001b[0;0m 0.105442176871\n",
      "\u001b[1mR SQUARED ERROR : \u001b[0;0m -0.0581678857541\n",
      "\u001b[1mCONFUSION MATRIX :\n",
      "\u001b[0;0m [[252   9]\n",
      " [ 22  11]]\n",
      "\u001b[1mCLASSIFICATION REPORT :\n",
      "\u001b[0;0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       261\n",
      "          1       0.55      0.33      0.42        33\n",
      "\n",
      "avg / total       0.88      0.89      0.88       294\n",
      "\n",
      "Stored 'accuracy' (float64)\n",
      "Stored 'cross_validation' (float64)\n",
      "Stored 'one_indices' (tuple)\n",
      "[[0.88435374149659862, 'LogisticRegression', (array([ 56,  67,  79,  87, 130, 145, 147, 154, 177, 190, 200, 240, 249,\n",
      "       268, 281], dtype=int64),), 0.85374149659863952], [0.89455782312925169, 'SelectKBest+LR', (array([  5,  56,  67,  71, 130, 154, 200, 240, 257, 268], dtype=int64),), 0.84693877551020391], [0.88775510204081631, 'SelectKBest+kNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'KNN', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'RecursiveFeatureElimination', (array([], dtype=int64),), 0.82653061224489799], [0.88775510204081631, 'RandomForest', (array([ 13,  41,  55,  56,  67,  87, 133, 142, 147, 157, 186, 191, 200,\n",
      "       202, 203, 238, 249, 286], dtype=int64),), 0.82653061224489788], [0.89455782312925169, 'XGBoost', (array([ 16,  30,  56,  67,  79,  87,  96, 106, 130, 142, 157, 168, 177,\n",
      "       186, 200, 240, 268, 281, 282, 289], dtype=int64),), 0.844387755102041]]\n",
      "[0.85374149659863952, 0.84693877551020391, 0.82653061224489799, 0.82653061224489799, 0.82653061224489799, 0.82653061224489788, 0.844387755102041]\n",
      "Stored 'accuracy_arr' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RetailAdmin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (17,) (20,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-791d52036542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'store -r accuracy_arr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_accuracy\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mmax_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'LogisticRegression'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (17,) (20,) "
     ]
    }
   ],
   "source": [
    "max_accuracy=[]\n",
    "lr=xgb=knn=skblr=skbknn=rfe=rf=knn=0\n",
    "for i in range(0,100,1) :\n",
    "    value=[]\n",
    "    %run Main.ipynb\n",
    "    %store -r accuracy_arr\n",
    "    value=max(accuracy_arr)\n",
    "    if(max_accuracy < value) :\n",
    "        max_accuracy=value\n",
    "    if max_accuracy[1]=='LogisticRegression' :\n",
    "        lr=lr+1\n",
    "    elif max_accuracy[1]=='XGBoost' :\n",
    "        xgb=xgb+1\n",
    "    elif max_accuracy[1]=='SelectKBest+LR' :\n",
    "        skblr=skblr+1\n",
    "    elif max_accuracy[1]=='SelectKBest+kNN' :\n",
    "        skbknn=skbknn+1\n",
    "    elif max_accuracy[1]=='RandomForest' :\n",
    "        rf=rf+1\n",
    "    elif max_accuracy[1]=='RecursiveFeatureElimination' :\n",
    "        rfe=rfe+1\n",
    "    else :\n",
    "        knn=knn+1\n",
    "    print(\"Final:\",max_accuracy)\n",
    "print (\"LR = \",lr)\n",
    "print(\"kNN = \",knn)\n",
    "print(\"RF = \",rf)\n",
    "print(\"RFE = \",rfe)\n",
    "print(\"SKB+LR = \",skblr)\n",
    "print(\"SKB+kNN = \",skbknn)\n",
    "print(\"XGB = \",xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EMPLOYEE NUMBERS OF EMPLOYEES WHO ARE LIKELY TO LEAVE :\")\n",
    "for i in max_accuracy[2] :\n",
    "    print(X_test.iloc[i,5].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
